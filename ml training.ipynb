{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import soundfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import re, os\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.preprocessing import feature_opensmile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_chromagram(waveform, sample_rate):\n",
    "    # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
    "    stft_spectrogram=np.abs(librosa.stft(waveform))\n",
    "    # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate).T,axis=0)\n",
    "    return chromagram\n",
    "\n",
    "def feature_melspectrogram(waveform, sample_rate, n_mels=128):\n",
    "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
    "    melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=n_mels, fmax=8000).T,axis=0)\n",
    "    return melspectrogram\n",
    "\n",
    "def feature_mfcc(waveform, sample_rate, n_mfcc=28):\n",
    "    # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
    "    # 40 filterbanks = 40 coefficients\n",
    "    mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=n_mfcc).T, axis=0) \n",
    "    return mfc_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import opensmile\n",
    "import audiofile\n",
    "import os\n",
    "import math\n",
    "\n",
    "def feature_opensmile(\n",
    "    waveform: np.ndarray,\n",
    "    sample_rate: int = 4000,\n",
    "    one_d: bool = False,\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    short: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the opensmile features for each 2 second. Step = 1 sec. there are 25 features in total.\n",
    "    If the input waveform is x seconds, then the output DataFrame will be x rowx * 25 columns.\n",
    "    Ref for eGeMAPSv02: https://sail.usc.edu/publications/files/eyben-preprinttaffc-2015.pdf\n",
    "    \"\"\"\n",
    "    smile = opensmile.Smile(\n",
    "        feature_set=feature_set,\n",
    "        feature_level=(\n",
    "            opensmile.FeatureLevel.LowLevelDescriptors\n",
    "            if one_d is False else\n",
    "            opensmile.FeatureLevel.Functionals\n",
    "        )\n",
    "    )\n",
    "    features_df = smile.process_signal(waveform, sample_rate)\n",
    "    if not short:\n",
    "        return features_df if one_d is False else features_df.to_numpy()[0]\n",
    "    else:\n",
    "        return features_df[\n",
    "            [  # use this\n",
    "                \"F3frequency_sma3nz\",\n",
    "                \"F3bandwidth_sma3nz\",\n",
    "                \"F2frequency_sma3nz\",\n",
    "                \"F2bandwidth_sma3nz\",\n",
    "                \"F1frequency_sma3nz\",\n",
    "                \"F1bandwidth_sma3nz\",\n",
    "                \"F3amplitudeLogRelF0_sma3nz\",\n",
    "                \"F1amplitudeLogRelF0_sma3nz\",\n",
    "                \"F2amplitudeLogRelF0_sma3nz\",\n",
    "                \"logRelF0-H1-A3_sma3nz\",\n",
    "            ]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chroma = 12\n",
    "n_mels = 128\n",
    "n_mfcc = 84\n",
    "\n",
    "def get_features(file):\n",
    "    # load an individual soundfile\n",
    "     with soundfile.SoundFile(file) as audio:\n",
    "        waveform = audio.read(dtype=\"float32\")\n",
    "        sample_rate = audio.samplerate # 4000\n",
    "        # compute features of soundfile\n",
    "        chromagram = feature_chromagram(waveform, sample_rate)\n",
    "        melspectrogram = feature_melspectrogram(waveform, sample_rate, n_mels)\n",
    "        mfc_coefficients = feature_mfcc(waveform, sample_rate, n_mfcc)\n",
    "        opensmile_fts = feature_opensmile(waveform, sample_rate, one_d=True)\n",
    "        \n",
    "        feature_matrix=np.array([])\n",
    "        # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
    "        feature_matrix = np.hstack((\n",
    "            chromagram,\n",
    "            melspectrogram,\n",
    "            mfc_coefficients,\n",
    "            opensmile_fts\n",
    "            ))\n",
    "        \n",
    "        return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2530: 0, 9979: 0, 9983: 0, 13918: 0, 14241: 0, 14998: 0, 23625: 0, 24160: 0, 29045: 0, 29378: 0, 31737: 0, 33151: 0, 36327: 0, 38337: 0, 39043: 0, 39403: 0, 39456: 0, 40058: 0, 40798: 0, 40840: 0, 43852: 1, 44514: 0, 45843: 0, 46065: 0, 46532: 1, 46579: 0, 46778: 0, 47002: 0, 49558: 0, 49561: 0, 49562: 0, 49568: 1, 49572: 1, 49574: 0, 49577: 1, 49585: 0, 49595: 0, 49598: 1, 49607: 0, 49610: 0, 49618: 0, 49622: 0, 49627: 0, 49628: 0, 49630: 0, 49631: 1, 49638: 0, 49641: 0, 49653: 1, 49659: 0, 49661: 1, 49669: 0, 49678: 1, 49683: 0, 49687: 0, 49691: 0, 49704: 0, 49712: 0, 49719: 1, 49729: 0, 49735: 0, 49745: 0, 49748: 0, 49751: 0, 49754: 0, 49761: 0, 49776: 0, 49808: 1, 49821: 0, 49823: 0, 49824: 0, 49829: 0, 49832: 1, 49838: 0, 49839: 1, 49842: 0, 49850: 0, 49853: 1, 49854: 0, 49873: 0, 49876: 0, 49896: 1, 49897: 1, 49900: 0, 49930: 1, 49931: 1, 49946: 0, 49952: 1, 49959: 1, 49960: 1, 49963: 0, 49966: 0, 49968: 1, 49969: 1, 49970: 1, 49974: 1, 49978: 0, 49979: 1, 49980: 0, 49983: 1, 49986: 1, 49987: 1, 49988: 1, 49989: 0, 49990: 1, 49993: 1, 49994: 0, 49995: 1, 49998: 1, 49999: 1, 50001: 1, 50004: 1, 50005: 1, 50006: 1, 50007: 1, 50008: 1, 50009: 1, 50012: 0, 50014: 1, 50015: 0, 50017: 1, 50018: 0, 50023: 1, 50026: 1, 50027: 1, 50029: 1, 50030: 0, 50032: 1, 50034: 1, 50037: 1, 50043: 1, 50047: 1, 50048: 1, 50049: 0, 50053: 1, 50054: 0, 50056: 0, 50057: 1, 50061: 0, 50066: 0, 50067: 0, 50070: 0, 50072: 0, 50074: 1, 50075: 1, 50076: 0, 50077: 1, 50078: 0, 50079: 1, 50080: 0, 50085: 1, 50086: 1, 50089: 0, 50092: 1, 50094: 1, 50096: 0, 50099: 1, 50100: 0, 50103: 1, 50104: 1, 50105: 1, 50109: 1, 50111: 0, 50113: 1, 50115: 0, 50116: 1, 50117: 1, 50118: 1, 50119: 1, 50121: 1, 50122: 1, 50123: 0, 50125: 0, 50126: 1, 50127: 0, 50128: 0, 50129: 1, 50133: 1, 50136: 0, 50137: 1, 50138: 1, 50141: 1, 50142: 1, 50143: 1, 50145: 1, 50146: 1, 50149: 0, 50150: 0, 50151: 0, 50152: 0, 50153: 0, 50155: 0, 50159: 0, 50160: 1, 50161: 0, 50164: 1, 50165: 0, 50166: 0, 50168: 1, 50174: 0, 50204: 1, 50206: 0, 50207: 0, 50209: 0, 50210: 1, 50213: 1, 50214: 1, 50216: 0, 50217: 0, 50218: 1, 50219: 0, 50220: 0, 50221: 1, 50222: 1, 50225: 1, 50228: 1, 50229: 0, 50230: 1, 50231: 1, 50233: 0, 50238: 0, 50239: 1, 50241: 0, 50244: 0, 50247: 1, 50248: 0, 50249: 1, 50250: 1, 50251: 1, 50254: 1, 50255: 0, 50256: 1, 50258: 1, 50260: 1, 50261: 0, 50263: 1, 50264: 1, 50271: 1, 50272: 1, 50273: 1, 50275: 1, 50276: 1, 50277: 0, 50278: 1, 50280: 0, 50281: 0, 50284: 1, 50285: 0, 50289: 0, 50291: 0, 50295: 0, 50296: 0, 50297: 0, 50298: 1, 50299: 1, 50300: 0, 50303: 0, 50304: 1, 50306: 0, 50311: 1, 50312: 0, 50314: 0, 50316: 1, 50317: 1, 50318: 0, 50319: 0, 50321: 0, 50323: 0, 50325: 0, 50326: 0, 50327: 1, 50330: 0, 50331: 0, 50332: 0, 50334: 1, 50335: 0, 50336: 1, 50337: 1, 50339: 1, 50341: 0, 50342: 0, 50343: 0, 50345: 1, 50348: 0, 50349: 1, 50350: 0, 50352: 1, 50354: 0, 50359: 0, 50375: 0, 50379: 0, 50384: 1, 50385: 1, 50386: 0, 50388: 1, 50391: 1, 50393: 0, 50619: 0, 50620: 1, 50621: 0, 50624: 0, 50625: 0, 50626: 0, 50628: 0, 50629: 0, 50631: 0, 50635: 1, 50636: 0, 50639: 1, 50640: 0, 50641: 1, 50643: 0, 50644: 1, 50645: 1, 50646: 1, 50647: 1, 50649: 0, 50652: 0, 50654: 1, 50655: 0, 50656: 1, 50657: 1, 50658: 1, 50659: 0, 50661: 1, 50664: 0, 50665: 0, 50667: 1, 50668: 0, 50669: 1, 50671: 0, 50673: 0, 50676: 1, 50677: 0, 50678: 0, 50680: 0, 50685: 0, 50687: 1, 50688: 1, 50689: 0, 50690: 0, 50691: 1, 50693: 0, 50699: 1, 50704: 1, 50707: 1, 50708: 0, 50713: 1, 50715: 1, 50720: 0, 50721: 0, 50722: 1, 50723: 0, 50725: 0, 50727: 0, 50729: 1, 50731: 1, 50732: 0, 50734: 0, 50735: 1, 50736: 0, 50737: 1, 50738: 0, 50739: 0, 50740: 0, 50742: 0, 50743: 1, 50744: 0, 50746: 0, 50747: 1, 50748: 1, 50749: 1, 50751: 1, 50752: 1, 50753: 1, 50754: 1, 50756: 1, 50757: 1, 50758: 1, 50762: 1, 50763: 0, 50766: 1, 50768: 1, 50770: 1, 50771: 0, 50772: 1, 50773: 0, 50774: 0, 50776: 0, 50781: 1, 50782: 0, 50784: 1, 50787: 1, 50788: 1, 50789: 0, 50790: 0, 50793: 1, 50795: 1, 50796: 0, 50797: 0, 50798: 1, 50800: 1, 50802: 1, 50803: 0, 50805: 1, 50807: 0, 50812: 0, 50815: 1, 50818: 0, 50819: 1, 50820: 1, 50822: 1, 50826: 0, 50829: 1, 51064: 1, 51331: 0, 55945: 0, 57700: 0, 57706: 0, 59536: 0, 61117: 0, 61610: 0, 63456: 0, 63581: 0, 64256: 0, 64715: 1, 68175: 0, 68182: 0, 68186: 1, 68194: 0, 68204: 0, 68213: 1, 68219: 0, 68222: 0, 68255: 0, 68260: 1, 68269: 0, 68279: 0, 68292: 0, 68298: 0, 68303: 0, 68306: 0, 68316: 1, 68318: 0, 68327: 0, 68330: 0, 68337: 1, 68347: 0, 68359: 0, 68363: 0, 68368: 0, 68374: 0, 68377: 0, 68379: 0, 68394: 1, 68395: 1, 68404: 1, 68406: 0, 68407: 1, 68412: 1, 68413: 1, 68419: 0, 68423: 0, 68425: 0, 68427: 1, 68431: 1, 68432: 0, 68435: 0, 68436: 1, 68444: 0, 68449: 1, 68456: 0, 68460: 1, 68465: 0, 68470: 1, 68477: 1, 68478: 0, 68482: 0, 68484: 0, 68487: 0, 68498: 0, 68504: 1, 68532: 0, 68545: 0, 68556: 0, 68560: 0, 68567: 0, 68576: 0, 68582: 0, 68624: 0, 68632: 0, 68646: 0, 68659: 0, 68660: 1, 68682: 0, 68698: 0, 68702: 0, 68705: 1, 68708: 0, 68711: 0, 68737: 0, 68738: 0, 68740: 0, 68741: 0, 68752: 1, 68755: 0, 68756: 1, 68757: 1, 68796: 1, 68827: 0, 68831: 0, 68849: 0, 68857: 0, 68861: 0, 68864: 0, 68874: 0, 68886: 1, 68887: 0, 68888: 0, 68895: 0, 68901: 1, 68908: 0, 68909: 0, 68952: 0, 69060: 0, 69066: 0, 69067: 1, 69068: 0, 69079: 0, 69093: 0, 69095: 0, 69096: 0, 69106: 0, 69112: 0, 69120: 0, 69125: 0, 69129: 0, 69141: 0, 69144: 1, 69147: 0, 69152: 0, 69155: 0, 69159: 0, 69161: 1, 69174: 0, 69176: 0, 69188: 0, 70280: 0, 72283: 0, 72288: 0, 73316: 0, 73497: 0, 74417: 0, 74420: 0, 75440: 0, 76240: 0, 76758: 0, 77373: 0, 78280: 0, 78582: 0, 78592: 0, 80348: 0, 81035: 0, 81297: 1, 81501: 0, 81638: 0, 82275: 1, 83094: 0, 84687: 1, 84688: 1, 84689: 1, 84690: 0, 84692: 0, 84693: 0, 84695: 1, 84696: 0, 84697: 1, 84699: 0, 84702: 0, 84704: 0, 84706: 0, 84708: 0, 84709: 1, 84710: 0, 84711: 1, 84713: 0, 84714: 0, 84716: 0, 84718: 0, 84720: 0, 84721: 0, 84724: 1, 84725: 1, 84727: 1, 84730: 1, 84731: 1, 84732: 0, 84733: 0, 84734: 0, 84735: 1, 84736: 0, 84738: 1, 84740: 1, 84742: 1, 84743: 1, 84746: 1, 84747: 1, 84749: 1, 84750: 1, 84751: 0, 84753: 1, 84754: 1, 84755: 1, 84758: 1, 84760: 1, 84761: 1, 84762: 1, 84764: 1, 84765: 1, 84768: 1, 84769: 1, 84775: 1, 84776: 1, 84778: 1, 84779: 1, 84780: 1, 84784: 1, 84785: 1, 84786: 1, 84790: 1, 84793: 1, 84796: 0, 84798: 1, 84799: 1, 84802: 1, 84803: 0, 84804: 1, 84805: 1, 84807: 1, 84808: 1, 84809: 1, 84813: 1, 84814: 1, 84815: 1, 84822: 1, 84823: 1, 84824: 0, 84826: 1, 84829: 1, 84831: 1, 84834: 0, 84835: 1, 84837: 0, 84838: 1, 84839: 1, 84840: 0, 84851: 0, 84852: 1, 84853: 0, 84854: 0, 84855: 1, 84856: 0, 84857: 0, 84859: 1, 84861: 1, 84863: 0, 84864: 1, 84865: 0, 84866: 1, 84868: 1, 84870: 0, 84874: 1, 84875: 1, 84876: 0, 84877: 1, 84878: 1, 84879: 1, 84881: 1, 84882: 0, 84883: 1, 84884: 1, 84885: 0, 84886: 1, 84887: 1, 84890: 1, 84892: 1, 84893: 1, 84894: 1, 84896: 1, 84900: 1, 84912: 1, 84917: 1, 84918: 1, 84919: 1, 84920: 1, 84921: 1, 84922: 1, 84923: 1, 84928: 1, 84930: 1, 84931: 0, 84933: 1, 84934: 0, 84935: 1, 84936: 1, 84937: 1, 84939: 1, 84942: 1, 84945: 1, 84946: 1, 84947: 0, 84949: 0, 84950: 0, 84952: 1, 84957: 1, 84960: 1, 84961: 1, 84962: 1, 84965: 0, 84966: 1, 84969: 0, 84970: 1, 84971: 1, 84973: 1, 84974: 1, 84976: 1, 84977: 1, 84978: 1, 84982: 1, 84983: 1, 84984: 0, 84985: 1, 84986: 1, 84987: 1, 84988: 1, 84990: 1, 84991: 1, 84992: 1, 84993: 0, 84994: 0, 84995: 1, 84996: 0, 85000: 1, 85002: 0, 85004: 0, 85010: 0, 85011: 1, 85012: 0, 85018: 0, 85019: 0, 85020: 0, 85023: 1, 85024: 0, 85026: 0, 85027: 1, 85028: 1, 85029: 1, 85030: 0, 85031: 0, 85033: 1, 85034: 0, 85035: 1, 85036: 0, 85037: 0, 85038: 0, 85042: 0, 85043: 1, 85044: 1, 85046: 1, 85048: 1, 85052: 0, 85053: 1, 85055: 0, 85057: 0, 85062: 1, 85063: 1, 85064: 1, 85066: 1, 85069: 0, 85075: 1, 85076: 1, 85077: 1, 85079: 0, 85080: 0, 85081: 0, 85084: 1, 85086: 1, 85087: 0, 85090: 1, 85091: 1, 85093: 1, 85094: 1, 85096: 1, 85099: 1, 85100: 1, 85102: 1, 85103: 1, 85105: 1, 85108: 0, 85109: 1, 85110: 1, 85112: 1, 85113: 1, 85114: 1, 85115: 1, 85116: 0, 85118: 1, 85119: 0, 85121: 1, 85122: 1, 85123: 1, 85124: 1, 85127: 0, 85128: 1, 85131: 1, 85132: 0, 85133: 0, 85134: 1, 85135: 1, 85136: 1, 85139: 0, 85140: 1, 85143: 1, 85144: 0, 85145: 0, 85147: 1, 85148: 1, 85150: 1, 85151: 1, 85152: 1, 85153: 1, 85154: 1, 85155: 1, 85157: 1, 85159: 1, 85161: 0, 85162: 0, 85163: 0, 85164: 1, 85165: 0, 85166: 1, 85167: 1, 85168: 1, 85169: 0, 85172: 0, 85174: 0, 85175: 1, 85176: 1, 85180: 1, 85181: 1, 85182: 1, 85184: 1, 85186: 1, 85192: 0, 85196: 1, 85197: 1, 85198: 0, 85199: 0, 85202: 0, 85203: 1, 85207: 0, 85210: 1, 85212: 1, 85213: 0, 85214: 1, 85216: 1, 85217: 1, 85219: 0, 85222: 1, 85225: 0, 85226: 1, 85227: 0, 85229: 1, 85230: 1, 85234: 1, 85235: 1, 85236: 0, 85239: 0, 85240: 1, 85241: 1, 85242: 1, 85243: 0, 85244: 0, 85245: 1, 85246: 1, 85247: 0, 85249: 1, 85250: 1, 85252: 1, 85253: 0, 85258: 1, 85259: 0, 85261: 0, 85262: 0, 85264: 1, 85265: 1, 85269: 1, 85270: 0, 85276: 0, 85277: 1, 85278: 0, 85279: 0, 85282: 1, 85285: 1, 85286: 1, 85287: 1, 85288: 1, 85293: 0, 85294: 0, 85296: 0, 85299: 1, 85300: 1, 85301: 1, 85305: 0, 85306: 0, 85308: 1, 85312: 1, 85313: 1, 85315: 0, 85316: 1, 85317: 1, 85319: 0, 85321: 1, 85322: 1, 85323: 1, 85326: 1, 85327: 1, 85328: 1, 85329: 1, 85331: 1, 85332: 1, 85334: 1, 85335: 1, 85336: 1, 85337: 1, 85338: 1, 85339: 1, 85340: 1, 85341: 1, 85343: 0, 85345: 1, 85349: 1}\n"
     ]
    }
   ],
   "source": [
    "dataset_info = pd.read_csv('assets/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data.csv')\n",
    "\n",
    "outcome_mapping = {'Normal': 1, 'Abnormal': 0}\n",
    "dataset_info['Mapped_Outcome'] = dataset_info['Outcome'].map(outcome_mapping)\n",
    "y_dict = dict(zip(dataset_info['Patient ID'], dataset_info['Mapped_Outcome']))\n",
    "\n",
    "print(y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13918_AV.wav',\n",
       " '13918_MV.wav',\n",
       " '13918_PV.wav',\n",
       " '13918_TV.wav',\n",
       " '14241_AV.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_files_by_keywords_and_extension(folder_path, keywords, extension):\n",
    "    filtered_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if any(keyword in filename for keyword in keywords) and filename.endswith(extension):\n",
    "            filtered_files.append(filename)\n",
    "    return filtered_files\n",
    "\n",
    "folder_path = 'assets/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data'\n",
    "keywords = ['TV','AV','PV','MV']\n",
    "extension = '.wav'\n",
    "\n",
    "filtered_files = filter_files_by_keywords_and_extension(folder_path, keywords, extension)\n",
    "filtered_files[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3159/3159 [1:03:57<00:00,  1.21s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data(filtered_files):\n",
    "    X, y = [], []\n",
    "    count = 0\n",
    "    for file in tqdm(filtered_files):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        features = get_features(file_path)\n",
    "        file_number = int(re.match(r'^([^_]*)', file)[1])\n",
    "        label = y_dict[file_number]\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        count += 1\n",
    "        # print('\\r' + f'Processed {count}/{len(filtered_files)} audio samples', end=' ')\n",
    "    print()  # Print a newline after the loop completes\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "features, labels = load_data(filtered_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(features).to_csv(\"./assets/feature.csv\", header=False, index=False)\n",
    "# features2 = np.array(pd.read_csv(\"./assets/feature.csv\", header=None))\n",
    "# features2.shape == features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many samples in total:  3159\n",
      "How many samples are Normal:  1632\n"
     ]
    }
   ],
   "source": [
    "print('How many samples in total: ', len(labels))\n",
    "\n",
    "print('How many samples are Normal: ', sum(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio samples represented: 3159\n",
      "Numerical features extracted per sample: 312\n",
      "n_chroma 12\n",
      "n_mels 128\n",
      "mfcc 84\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nAudio samples represented: {features.shape[0]}')\n",
    "print(f'Numerical features extracted per sample: {features.shape[1]}')\n",
    "features_df = pd.DataFrame(features) # make it pretty for display\n",
    "features_df\n",
    "\n",
    "\n",
    "\n",
    "print('n_chroma', n_chroma)\n",
    "print('n_mels',n_mels)\n",
    "print('mfcc', n_mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Chromagram features:           min = 0.164,     max = 0.997,     mean = 0.808,     deviation = 0.076\n",
      "\n",
      "128 Mel Spectrogram features:     min = 0.000,     max = 4547.607,     mean = 1.039,     deviation = 12.969\n",
      "\n",
      "84 MFCC features:                 min = -344.715,    max = 197.198,    mean = -1.062,    deviation = 26.660\n"
     ]
    }
   ],
   "source": [
    "# We would usually use df.describe(), but it provides a bit of a mess of information we don't need at the moment.\n",
    "def print_features(df):\n",
    "    # Check chromagram feature values\n",
    "    features_df_chromagram = df.loc[:,:11]\n",
    "    chroma_min = features_df_chromagram.min().min()\n",
    "    chroma_max = features_df_chromagram.max().max()\n",
    "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
    "    chroma_mean = features_df_chromagram.stack().mean()\n",
    "    chroma_stdev = features_df_chromagram.stack().std()\n",
    "    print(f'{n_chroma} Chromagram features:       \\\n",
    "    min = {chroma_min:.3f}, \\\n",
    "    max = {chroma_max:.3f}, \\\n",
    "    mean = {chroma_mean:.3f}, \\\n",
    "    deviation = {chroma_stdev:.3f}') \n",
    "\n",
    "    # Check mel spectrogram feature values\n",
    "    features_df_melspectrogram = df.loc[:,n_chroma:n_chroma+n_mels-1]\n",
    "    mel_min = features_df_melspectrogram.min().min()\n",
    "    mel_max = features_df_melspectrogram.max().max()\n",
    "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
    "    mel_mean = features_df_melspectrogram.stack().mean()\n",
    "    mel_stdev = features_df_melspectrogram.stack().std()\n",
    "    print(f'\\n{n_mels} Mel Spectrogram features: \\\n",
    "    min = {mel_min:.3f}, \\\n",
    "    max = {mel_max:.3f}, \\\n",
    "    mean = {mel_mean:.3f}, \\\n",
    "    deviation = {mel_stdev:.3f}')\n",
    "\n",
    "    # Check MFCC feature values\n",
    "    features_df_mfcc = df.loc[:,n_chroma+n_mels:n_chroma+n_mels+n_mfcc-1]\n",
    "    mfcc_min = features_df_mfcc.min().min()\n",
    "    mfcc_max = features_df_mfcc.max().max()\n",
    "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
    "    mfcc_mean = features_df_mfcc.stack().mean()\n",
    "    mfcc_stdev = features_df_mfcc.stack().std()\n",
    "    print(f'\\n{n_mfcc} MFCC features:             \\\n",
    "    min = {mfcc_min:.3f},\\\n",
    "    max = {mfcc_max:.3f},\\\n",
    "    mean = {mfcc_mean:.3f},\\\n",
    "    deviation = {mfcc_stdev:.3f}')\n",
    "    \n",
    "print_features(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# keep our unscaled features just in case we need to process them alternatively\n",
    "features_scaled = features \n",
    "features_scaled = scaler.fit_transform(features_scaled)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# keep our unscaled features just in case we need to process them alternatively\n",
    "features_minmax = features\n",
    "features_minmax = scaler.fit_transform(features_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mStandard Scaling:\n",
      "\u001b[0m\n",
      "12 Chromagram features:           min = -12.385,     max = 3.475,     mean = 0.000,     deviation = 1.000\n",
      "\n",
      "128 Mel Spectrogram features:     min = -0.536,     max = 54.209,     mean = -0.000,     deviation = 0.750\n",
      "\n",
      "84 MFCC features:                 min = -9.718,    max = 10.532,    mean = -0.000,    deviation = 1.000\n",
      "\n",
      "\n",
      "\u001b[1mMinMax Scaling:\n",
      "\u001b[0m\n",
      "12 Chromagram features:           min = 0.000,     max = 1.000,     mean = 0.784,     deviation = 0.105\n",
      "\n",
      "128 Mel Spectrogram features:     min = 0.000,     max = 1.000,     mean = 0.004,     deviation = 0.026\n",
      "\n",
      "84 MFCC features:                 min = 0.000,    max = 1.000,    mean = 0.491,    deviation = 0.141\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m'+'Standard Scaling:\\n'+'\\033[0m')\n",
    "features_scaled_df = pd.DataFrame(features_scaled)\n",
    "print_features(features_scaled_df)\n",
    "\n",
    "print('\\n\\n\\033[1m'+'MinMax Scaling:\\n'+'\\033[0m')\n",
    "features_minmax_df = pd.DataFrame(features_minmax)\n",
    "print_features(features_minmax_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "############ Unscaled test/train set #############\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=69\n",
    ")\n",
    "\n",
    "############ Standard Scaled test/train set ###########\n",
    "# The labels/classes (y_train, y_test) never change, keep old values \n",
    "X_train_scaled, X_test_scaled, _, _ = train_test_split(\n",
    "    features_scaled, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=69\n",
    ")\n",
    "\n",
    "############# MinMax Scaled test/train set ###############\n",
    "# The labels/classes (y_train, y_test) never change, keep old values \n",
    "X_train_minmax, X_test_minmax, _, _ = train_test_split(\n",
    "    features_minmax, \n",
    "    labels, \n",
    "    test_size=0.2, \n",
    "    random_state=69\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classification_models = {\n",
    "    \"knn\": KNeighborsClassifier(),#(3),\n",
    "    \"svc\": SVC(kernel='linear'),#, C=0.025),\n",
    "    \"svc-rbf\": SVC(kernel='rbf'),\n",
    "    \"decision tree\": DecisionTreeClassifier(),#max_depth=5),\n",
    "    \"random forest\": RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"ada boost\": AdaBoostClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model: knn\n",
      "training model: svc\n",
      "training model: svc-rbf\n",
      "training model: decision tree\n",
      "training model: random forest\n",
      "training model: ada boost\n",
      "training model: GaussianNB\n",
      "training model: QDA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>58.39%</td>\n",
       "      <td>0.575074</td>\n",
       "      <td>0.637241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>58.39%</td>\n",
       "      <td>0.583866</td>\n",
       "      <td>0.605697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>57.75%</td>\n",
       "      <td>0.568687</td>\n",
       "      <td>0.631724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>57.44%</td>\n",
       "      <td>0.573679</td>\n",
       "      <td>0.599106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>55.22%</td>\n",
       "      <td>0.549204</td>\n",
       "      <td>0.586861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>55.06%</td>\n",
       "      <td>0.512288</td>\n",
       "      <td>0.690632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC RBF kernel</td>\n",
       "      <td>53.80%</td>\n",
       "      <td>0.515583</td>\n",
       "      <td>0.640394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>45.57%</td>\n",
       "      <td>0.502587</td>\n",
       "      <td>0.017143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classifier Accuracy Score       AUC  F1 Score\n",
       "4         RandomForestClassifier         58.39%  0.575074  0.637241\n",
       "5             AdaBoostClassifier         58.39%  0.583866  0.605697\n",
       "1                            SVC         57.75%  0.568687  0.631724\n",
       "3         DecisionTreeClassifier         57.44%  0.573679  0.599106\n",
       "0           KNeighborsClassifier         55.22%  0.549204  0.586861\n",
       "6                     GaussianNB         55.06%  0.512288  0.690632\n",
       "2                 SVC RBF kernel         53.80%  0.515583  0.640394\n",
       "7  QuadraticDiscriminantAnalysis         45.57%  0.502587  0.017143"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "scores = []\n",
    "for model_name in classification_models:\n",
    "    print(f\"training model: {model_name}\")\n",
    "    model = classification_models[model_name]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)  # Calculate AUC\n",
    "    f1 = f1_score(y_test, y_pred)  # Calculate F1 score\n",
    "    score = model.score(X_test, y_test)\n",
    "    model_name = type(model).__name__\n",
    "    if model_name == 'SVC' and model.kernel == 'rbf':\n",
    "        model_name += ' RBF kernel'\n",
    "    print(f'{100*score:.2f}% auc={auc} f1={f1}')\n",
    "    scores.append((model_name, f'{100*score:.2f}%', auc, f1))  # Add AUC and F1 score to scores list\n",
    "# Make it pretty\n",
    "scores_df = pd.DataFrame(scores, columns=['Classifier', 'Accuracy Score', 'AUC', 'F1 Score'])\n",
    "scores_df.sort_values(by='Accuracy Score', axis=0, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "if not os.path.exists(\"models\"):\n",
    "    os.mkdir(\"models\")\n",
    "    \n",
    "for model_name in classification_models:\n",
    "    print(f\"saving model: {model_name}\")\n",
    "    model = classification_models[model_name]\n",
    "    dump(model, f'./models/{model_name}.joblib')\n",
    "    # classification_models[model_name] = load(f'./models/{model_name}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for model_name in classification_models:\n",
    "    print(f\"training model: {model_name}\")\n",
    "    model = classification_models[model_name]\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    model_name = type(model).__name__\n",
    "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
    "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
    "# Make it pretty\n",
    "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
    "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziaoyou/WorkSpace/CodeSpace/Projects/HeartDiseasePrediction/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/ziaoyou/WorkSpace/CodeSpace/Projects/HeartDiseasePrediction/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC RBF kernel</td>\n",
       "      <td>66.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>65.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>62.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>59.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>56.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>55.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>54.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>49.53%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classifier Accuracy Score\n",
       "2                 SVC RBF kernel         66.14%\n",
       "4         RandomForestClassifier         65.03%\n",
       "1                            SVC         62.34%\n",
       "5             AdaBoostClassifier         59.02%\n",
       "0           KNeighborsClassifier         56.49%\n",
       "7  QuadraticDiscriminantAnalysis         55.85%\n",
       "6                     GaussianNB         54.75%\n",
       "3         DecisionTreeClassifier         49.53%"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for model_name in classification_models:\n",
    "    print(f\"training model: {model_name}\")\n",
    "    model = classification_models[model_name]\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    score = model.score(X_test_scaled, y_test)\n",
    "    model_name = type(model).__name__\n",
    "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
    "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
    "# Make it pretty\n",
    "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
    "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziaoyou/WorkSpace/CodeSpace/Projects/HeartDiseasePrediction/.venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/ziaoyou/WorkSpace/CodeSpace/Projects/HeartDiseasePrediction/.venv/lib/python3.11/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>63.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC RBF kernel</td>\n",
       "      <td>61.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>60.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>59.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>59.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>56.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>54.75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>50.32%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Classifier Accuracy Score\n",
       "1                            SVC         63.77%\n",
       "2                 SVC RBF kernel         61.23%\n",
       "4         RandomForestClassifier         60.76%\n",
       "7  QuadraticDiscriminantAnalysis         59.49%\n",
       "5             AdaBoostClassifier         59.02%\n",
       "0           KNeighborsClassifier         56.01%\n",
       "6                     GaussianNB         54.75%\n",
       "3         DecisionTreeClassifier         50.32%"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for model in classification_models:\n",
    "    model.fit(X_train_minmax, y_train)\n",
    "    score = model.score(X_test_minmax, y_test)\n",
    "    model_name = type(model).__name__\n",
    "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
    "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
    "# Make it pretty\n",
    "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
    "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Model's accuracy on training set is 100.00%\n",
      "SVC Model's accuracy on test set is 56.96%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(\n",
    "    C=10,\n",
    "    gamma='auto',\n",
    "    kernel='rbf',\n",
    "    random_state=69\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default kNN Model's accuracy on training set is 73.13%\n",
      "Default kNN Model's accuracy on test set is 63.13%\n",
      "\n",
      "kNN Model's accuracy on training set is 100.00%\n",
      "kNN Model's accuracy on test set is 63.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "####### Default kNN  ########\n",
    "model = KNeighborsClassifier(\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Default kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
    "print(f'Default kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
    "\n",
    "##### (hastily) tuned kNN ######\n",
    "model = KNeighborsClassifier(\n",
    "    n_neighbors = 5,\n",
    "    weights = 'distance',\n",
    "    algorithm = 'brute',\n",
    "    leaf_size = 30,\n",
    "    n_jobs=5\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
    "print(f'kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Random Forest Model's accuracy on training set is 100.00%\n",
      "Default Random Forest Model's accuracy on test set is 63.45%\n",
      "\n",
      "Random Forest Model's accuracy on training set is 100.00%\n",
      "Random Forest Model's accuracy on test set is 64.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "####### Default Random Forest ########\n",
    "model = RandomForestClassifier(\n",
    "    random_state=69\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Default Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
    "print(f'Default Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
    "\n",
    "\n",
    "########## Tuned Random Forest #######\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators = 500, \n",
    "    criterion ='entropy',\n",
    "    warm_start = True,\n",
    "    max_features = 'sqrt',\n",
    "    oob_score = True, # more on this below\n",
    "    random_state=69  \n",
    ") \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f'Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
    "print(f'Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
